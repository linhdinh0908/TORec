{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3. Training and Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "tfod"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKiMc_fnDLNf"
      },
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "outputId": "88748223-fec2-4478-fd95-39f9534a786c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 61241, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 61241 (delta 2), reused 8 (delta 0), pack-reused 61231\u001b[K\n",
            "Receiving objects: 100% (61241/61241), 574.12 MiB | 28.89 MiB/s, done.\n",
            "Resolving deltas: 100% (42604/42604), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "outputId": "e659a0f5-d627-4ed8-8619-53266364a2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 17.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.3 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 47 kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text>=2.5.0\n",
            "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.34.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.39.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 29.9 MB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 43.4 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 751 kB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1664548 sha256=7812daad8d10d795ae465d850806e113c83968783e64f77fdfd8202a05228af5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g6g7g4fi/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=5082408d767a824ee32110a564d9e155a11ea13ccd4a09a7db749ea19f1c8344\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=0cb4935473b77410b6e3030940866abf067c158b8ffe1cda62b38e7d7262e51d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=665b3193ffbca80b81fa04b6e83e67c2683b815d47bfc79f7a5b17e4887a0a1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c84d7bfd8a27d1665e64840c9b3bd0961b9a99e3570df046c673c1e53cf4aa56\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=5b65141e73c86bf06fea6050c5a8b916475f0522bee0924cc0cedfb14b66ed85\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n",
            "Installing collected packages: requests, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sP9RyrYJDLNh",
        "outputId": "a73c2da7-4429-4f6f-9508-f71e69794851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-03 00:30:29.551620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:30.243433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:30.244298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Running tests under Python 3.7.11: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-09-03 00:30:30.260112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:30.260891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:30.261707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:35.246430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:35.247379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:35.248168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:30:35.248913: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-09-03 00:30:35.249118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "W0903 00:30:35.579439 139914753546112 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 5.75s\n",
            "I0903 00:30:35.998934 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 5.75s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.6s\n",
            "I0903 00:30:36.599338 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.6s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
            "I0903 00:30:36.937660 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "I0903 00:30:37.256686 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0903 00:30:37.259330 139914753546112 mobilenet_v2.py:297] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.55s\n",
            "I0903 00:30:39.811334 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.55s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0903 00:30:39.812462 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0903 00:30:39.838708 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0903 00:30:39.855900 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0903 00:30:39.874407 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "I0903 00:30:39.995692 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "I0903 00:30:40.114705 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "I0903 00:30:40.234476 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "I0903 00:30:40.358521 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "I0903 00:30:40.479999 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0903 00:30:40.513337 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0903 00:30:40.866358 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0903 00:30:40.866548 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0903 00:30:40.866657 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0903 00:30:40.869219 139914753546112 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0903 00:30:40.888906 139914753546112 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0903 00:30:40.889087 139914753546112 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0903 00:30:40.959686 139914753546112 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0903 00:30:40.959856 139914753546112 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0903 00:30:41.144680 139914753546112 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0903 00:30:41.144860 139914753546112 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0903 00:30:41.320633 139914753546112 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0903 00:30:41.320829 139914753546112 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0903 00:30:41.603160 139914753546112 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0903 00:30:41.603377 139914753546112 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0903 00:30:41.880195 139914753546112 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0903 00:30:41.880398 139914753546112 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0903 00:30:42.260654 139914753546112 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0903 00:30:42.260841 139914753546112 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0903 00:30:42.347490 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0903 00:30:42.383925 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:30:42.455022 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0903 00:30:42.455239 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0903 00:30:42.455348 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0903 00:30:42.457358 139914753546112 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0903 00:30:42.476217 139914753546112 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0903 00:30:42.476372 139914753546112 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0903 00:30:42.623751 139914753546112 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0903 00:30:42.623979 139914753546112 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0903 00:30:42.892128 139914753546112 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0903 00:30:42.892329 139914753546112 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0903 00:30:43.172832 139914753546112 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0903 00:30:43.173037 139914753546112 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0903 00:30:43.566904 139914753546112 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0903 00:30:43.567157 139914753546112 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0903 00:30:43.934386 139914753546112 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0903 00:30:43.934582 139914753546112 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0903 00:30:44.394586 139914753546112 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0903 00:30:44.394793 139914753546112 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0903 00:30:44.581674 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0903 00:30:44.615447 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:30:44.824418 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0903 00:30:44.824612 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0903 00:30:44.824724 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0903 00:30:44.826801 139914753546112 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0903 00:30:44.844876 139914753546112 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0903 00:30:44.845021 139914753546112 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0903 00:30:44.996902 139914753546112 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0903 00:30:44.997346 139914753546112 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0903 00:30:45.290979 139914753546112 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0903 00:30:45.291174 139914753546112 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0903 00:30:45.571759 139914753546112 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0903 00:30:45.571989 139914753546112 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0903 00:30:45.936498 139914753546112 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0903 00:30:45.936705 139914753546112 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0903 00:30:46.309334 139914753546112 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0903 00:30:46.309563 139914753546112 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0903 00:30:46.769016 139914753546112 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0903 00:30:46.769254 139914753546112 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0903 00:30:46.964170 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0903 00:30:46.997758 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:30:47.076937 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0903 00:30:47.077149 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0903 00:30:47.077260 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0903 00:30:47.079235 139914753546112 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0903 00:30:47.098642 139914753546112 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0903 00:30:47.098770 139914753546112 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0903 00:30:47.245376 139914753546112 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0903 00:30:47.245582 139914753546112 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0903 00:30:47.523938 139914753546112 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0903 00:30:47.524248 139914753546112 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0903 00:30:47.798595 139914753546112 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0903 00:30:47.798780 139914753546112 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0903 00:30:48.251381 139914753546112 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0903 00:30:48.251584 139914753546112 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0903 00:30:48.716113 139914753546112 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0903 00:30:48.716327 139914753546112 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0903 00:30:49.277038 139914753546112 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0903 00:30:49.277243 139914753546112 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0903 00:30:49.460137 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0903 00:30:49.494902 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:30:49.810778 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0903 00:30:49.810997 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0903 00:30:49.811121 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0903 00:30:49.813147 139914753546112 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0903 00:30:49.832153 139914753546112 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0903 00:30:49.832304 139914753546112 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0903 00:30:49.982105 139914753546112 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0903 00:30:49.982331 139914753546112 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0903 00:30:50.358395 139914753546112 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0903 00:30:50.358599 139914753546112 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0903 00:30:50.763332 139914753546112 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0903 00:30:50.763526 139914753546112 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0903 00:30:51.325396 139914753546112 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0903 00:30:51.325599 139914753546112 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0903 00:30:51.893655 139914753546112 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0903 00:30:51.893848 139914753546112 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0903 00:30:52.645358 139914753546112 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0903 00:30:52.645560 139914753546112 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0903 00:30:52.831121 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0903 00:30:52.864358 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:30:52.961663 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0903 00:30:52.961845 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0903 00:30:52.961966 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0903 00:30:52.963917 139914753546112 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0903 00:30:52.982159 139914753546112 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0903 00:30:52.982291 139914753546112 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0903 00:30:53.206781 139914753546112 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0903 00:30:53.207094 139914753546112 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0903 00:30:53.678415 139914753546112 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0903 00:30:53.678608 139914753546112 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0903 00:30:54.157089 139914753546112 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0903 00:30:54.157321 139914753546112 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0903 00:30:54.798676 139914753546112 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0903 00:30:54.798882 139914753546112 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0903 00:30:55.729061 139914753546112 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0903 00:30:55.729276 139914753546112 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0903 00:30:56.564251 139914753546112 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0903 00:30:56.564480 139914753546112 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0903 00:30:56.855253 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0903 00:30:56.890603 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:30:57.005715 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0903 00:30:57.005929 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0903 00:30:57.006059 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0903 00:30:57.008094 139914753546112 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0903 00:30:57.027243 139914753546112 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0903 00:30:57.027377 139914753546112 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0903 00:30:57.248648 139914753546112 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0903 00:30:57.248840 139914753546112 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0903 00:30:57.812283 139914753546112 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0903 00:30:57.812556 139914753546112 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0903 00:30:58.371334 139914753546112 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0903 00:30:58.371534 139914753546112 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0903 00:30:59.095541 139914753546112 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0903 00:30:59.095753 139914753546112 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0903 00:30:59.852665 139914753546112 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0903 00:30:59.852859 139914753546112 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0903 00:31:01.133463 139914753546112 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0903 00:31:01.133657 139914753546112 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0903 00:31:01.413623 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0903 00:31:01.447770 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0903 00:31:01.569175 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0903 00:31:01.569386 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0903 00:31:01.569508 139914753546112 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0903 00:31:01.571440 139914753546112 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0903 00:31:01.590358 139914753546112 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0903 00:31:01.590497 139914753546112 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0903 00:31:01.908007 139914753546112 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0903 00:31:01.908214 139914753546112 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0903 00:31:02.553197 139914753546112 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0903 00:31:02.553398 139914753546112 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0903 00:31:03.196982 139914753546112 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0903 00:31:03.197238 139914753546112 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0903 00:31:04.114774 139914753546112 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0903 00:31:04.115000 139914753546112 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0903 00:31:05.040585 139914753546112 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0903 00:31:05.040786 139914753546112 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0903 00:31:06.235645 139914753546112 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0903 00:31:06.235845 139914753546112 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0903 00:31:06.879195 139914753546112 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0903 00:31:06.913324 139914753546112 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.55s\n",
            "I0903 00:31:07.060587 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.55s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0903 00:31:07.068386 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0903 00:31:07.070391 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0903 00:31:07.071010 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0903 00:31:07.073043 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0903 00:31:07.075519 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0903 00:31:07.076156 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0903 00:31:07.077509 139914753546112 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 36.829s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OXbbVgsLDLNh",
        "outputId": "96a6a402-e458-47a7-dbdc-681790121a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.39.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hmB5FIaNDLNi",
        "outputId": "3f575bc3-71a5-4da0-cd16-f29a4e56c1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: protobuf 3.17.3\n",
            "Uninstalling protobuf-3.17.3:\n",
            "  Successfully uninstalled protobuf-3.17.3\n",
            "Found existing installation: matplotlib 3.2.2\n",
            "Uninstalling matplotlib-3.2.2:\n",
            "  Successfully uninstalled matplotlib-3.2.2\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.2\n",
            "  Downloading matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 159 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.17.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNmEPW3KDLNi"
      },
      "source": [
        "import object_detection"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6uq-xAxtDLNi",
        "outputId": "18f2a013-7bab-4e6c-b77b-deb69912e382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.1.0\n",
            "apache-beam                   2.32.0\n",
            "appdirs                       1.4.4\n",
            "argcomplete                   1.12.3\n",
            "argon2-cffi                   21.1.0\n",
            "arviz                         0.11.2\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.2.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.3\n",
            "avro-python3                  1.9.2.1\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        4.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.2\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.6\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.2\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.5.30\n",
            "cffi                          1.14.6\n",
            "cftime                        1.5.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.4\n",
            "clang                         5.0\n",
            "click                         7.1.2\n",
            "cloudpickle                   1.3.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorama                      0.4.4\n",
            "colorcet                      2.0.6\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.3.2\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda101                  9.1.0\n",
            "cvxopt                        1.2.6\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.10.0\n",
            "cymem                         2.0.5\n",
            "Cython                        0.29.24\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.6\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.278\n",
            "easydict                      1.9\n",
            "ecos                          2.0.7.post1\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.3\n",
            "ephem                         4.0.0.2\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastavro                      1.4.4\n",
            "fastdtw                       0.3.4\n",
            "fastprogress                  1.0.0\n",
            "fastrlock                     0.6\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.0.12\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.8.3\n",
            "future                        0.18.2\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         3.6.4\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.4.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.26.3\n",
            "google-api-python-client      1.12.8\n",
            "google-auth                   1.34.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.5\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.0\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.53.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.1\n",
            "grpcio                        1.39.0\n",
            "gspread                       3.0.1\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.6.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.1.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.5\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.2.0\n",
            "imbalanced-learn              0.4.3\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.6.4\n",
            "importlib-resources           5.2.2\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2021.3.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.6.3\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.2.19\n",
            "jaxlib                        0.1.70+cuda110\n",
            "jdcal                         1.4.1\n",
            "jedi                          0.18.0\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.0.1\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    2.6.0\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.7.1\n",
            "jupyterlab-pygments           0.1.2\n",
            "jupyterlab-widgets            1.0.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.5\n",
            "keras                         2.6.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.3.1\n",
            "korean-lunar-calendar         0.2.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.4\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.0\n",
            "matplotlib-inline             0.1.2\n",
            "matplotlib-venn               0.11.6\n",
            "missingno                     0.5.0\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.8.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.2\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.9\n",
            "murmurhash                    1.0.5\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.5.4\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.1.3\n",
            "nest-asyncio                  1.5.1\n",
            "netCDF4                       1.5.7\n",
            "networkx                      2.6.2\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.7.3\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.1\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.5.3.56\n",
            "openpyxl                      2.5.9\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.6.3\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.1.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.4.3\n",
            "panel                         0.12.1\n",
            "param                         1.11.1\n",
            "parso                         0.8.2\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.1\n",
            "pep517                        0.11.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        4.4.1\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.4.0\n",
            "portalocker                   2.3.2\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.5\n",
            "prettytable                   2.1.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.11.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "protobuf                      3.17.3\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.10.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       3.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.2\n",
            "pycparser                     2.20\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.2.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.2\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.5\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.15\n",
            "python-slugify                5.0.2\n",
            "python-utils                  2.5.6\n",
            "pytz                          2018.9\n",
            "pyviz-comms                   2.1.0\n",
            "PyWavelets                    1.1.1\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         22.2.1\n",
            "qdldl                         0.1.5.post0\n",
            "qtconsole                     5.1.1\n",
            "QtPy                          1.10.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.26.0\n",
            "requests-oauthlib             1.3.0\n",
            "resampy                       0.2.2\n",
            "retrying                      1.3.3\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.7.2\n",
            "sacrebleu                     2.0.0\n",
            "scikit-image                  0.16.2\n",
            "scikit-learn                  0.22.2.post1\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           2.1.4\n",
            "seaborn                       0.11.1\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.96\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.7.1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.1.0\n",
            "snowballstemmer               2.1.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.5\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.22\n",
            "sqlparse                      0.4.1\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.4.4\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tensorboard                   2.6.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.0\n",
            "tensorflow                    2.6.0\n",
            "tensorflow-addons             0.14.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.6.0\n",
            "tensorflow-gcs-config         2.6.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-metadata           1.2.0\n",
            "tensorflow-model-optimization 0.6.0\n",
            "tensorflow-probability        0.13.0\n",
            "tensorflow-text               2.6.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.11.0\n",
            "testpath                      0.5.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.6.0\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "tifffile                      2021.8.30\n",
            "toml                          0.10.2\n",
            "tomli                         1.2.1\n",
            "toolz                         0.11.1\n",
            "torch                         1.9.0+cu102\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.10.0\n",
            "torchvision                   0.10.0+cu102\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.62.0\n",
            "traitlets                     5.0.5\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.7.4.3\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.8.2\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.0\n",
            "widgetsnbextension            3.5.1\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.12.1\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   0.9.1\n",
            "zict                          2.0.0\n",
            "zipp                          3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "4a58ff1f-f0b9-43c2-89d4-1a59b9be7d93"
      },
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-03 00:32:09--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.74.128, 2607:f8b0:4001:c0d::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.74.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-03 00:32:10 (165 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "source": [
        "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'ThankYou', 'id':3}, {'name':'LiveLong', 'id':4}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvf5WccwrFGq",
        "outputId": "098f69ff-70b2-464f-acd6-026ff5308930"
      },
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow/workspace/images/train/\n",
            "Tensorflow/workspace/images/test/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpb_BVUpfDD",
        "outputId": "7ed72613-339e-41e8-9e1c-f474a640965e"
      },
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "235b59c1-a435-4584-bb36-faa03e02c83e"
      },
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "71dd1ac3-61c2-482b-813e-7b1751f33fc0"
      },
      "source": [
        "config"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "fb00a6cd-942e-4472-8f83-90da1b744ec9"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "a6b9183f-ee87-48d6-8281-552709616877"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-03 00:33:23.469800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.488201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.488967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.490544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.491371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.492119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.976656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.977521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.978338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-03 00:33:23.979061: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-09-03 00:33:23.979136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0903 00:33:23.984373 140548156503936 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0903 00:33:23.989125 140548156503936 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0903 00:33:23.989301 140548156503936 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0903 00:33:24.120491 140548156503936 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0903 00:33:24.132823 140548156503936 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0903 00:33:24.133118 140548156503936 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0903 00:33:24.133260 140548156503936 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0903 00:33:24.133409 140548156503936 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0903 00:33:24.146816 140548156503936 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0903 00:33:24.177059 140548156503936 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0903 00:33:32.718878 140548156503936 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0903 00:33:36.627272 140548156503936 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0903 00:33:38.770955 140548156503936 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-09-03 00:33:41.554900: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYsgEPx9pfDH"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTV2jGBpfDH"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpzn1SMry1yK"
      },
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "022dN6yhDLNm"
      },
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGaPMBdoDLNn"
      },
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whShhB0x3PYJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}